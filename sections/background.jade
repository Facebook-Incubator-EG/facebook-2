doctype html
html
  head
    link(rel='stylesheet', href='/css/index.css')
    link(rel='stylesheet', href='/css/bootstrap.css')
    meta(charset="utf-8")
    meta(http-equiv="X-UA-Compatible" content="IE=edge")
    meta(name="viewport" content="width=device-width, initial-scale=1")
    title background thoughts on facebook.tracking.exposed

  body
 
    div.jumbotron
      div.head-text.fb-color
        div.container-fluid
          h2 backgound thoughts on 
          h1.center 
            a(href="/") ઉ
            | facebook.tracking.exposed

    div.propaganda

      p I made facebook.tracking.exposed and I believe it is a legitimate idea, but it has been told to me that following some interpretations, the Terms of Service of Facebook might forbid it.

      p I decided to continue anyway, and accept eventual legal consequences, because the right to be informed, the role of the journalist, and the neutrality of the systems of data transport are currently under debate and deserve a reflection and an update.

      p When our information was driven by TV and newspapers, it was easier to understand the political line of every publisher or editor. The views of each publisher could be easily discerned, and the reader could know on which topics each publisher would be more balanced, or sensible.

      p By 2016, the digital platform had changed the way information is used and contextualized, building visions of the world personalized by each user’s profiled behavior. This automation distorts the perception of reality and the way we interact with it. It has critical effects on the learning process, on the behavior, on the political participation, and on human relationships.

      p The algorithms used by the platforms do not modify the published content, but rather evaluate their appropriateness. This is based on secret rankings that are completely arbitrary and potentially discriminating. Manipulating the number and the priority of accesses to a specific topic, for example, our experience with the platform may have very different changes according to the users’ behaviour.  At the end of the day, the algorithm manipulates our experience and our impressions. On one side, some contents are penalized till hidden censorship. On the other side, other contents are promoted with propagandist iterations.

      p We have evidences that Facebook, and quite likely other platforms, have done experiments with their users and developed services in which value depends on this misrepresentation of reality and on this mechanisms of users’ preferences manipulation. The users are a market to exploit, a target, rather than participants in a market of public ideas. Their own preferences, based on genuine interest, become something to be exploited by corporations, and can lead to a distorted sense of reality.

      p So I felt the need to create a method of comparison between users: Is Facebook prioritizing the same information for me and you?  What am I losing? And what content is promoted or penalized?

      p I issued this tool so that every user can, if he wants, observe how happens the building of preferences. Facebook.tracking.exposed works like a personal assistant: It analyses with you the order of the posts in your feed, displaying to you what has been penalized or promoted.

      p Facebook.tracking.exposed extracts metadata. Not content, but metrics, numbers. What we get from my analysis are shares, times and iterations.These data are enough to show a small part of what happens “behind the curtain” at Facebook.

      p Facebook.tracking.exposed is not really rocket science. What you have is the same result that you will get if, for example, a couple sitting next to each other, both looking at their Facebook feeds, tries to understand if (their?) reality was changed, how and how much. They share political views, and notice that similar content is being served to them, albeit in a different order, and with different details. Together, they are able to see how the platform distorts reality, but normally, this is not how users of these platforms interact with each other. 

      p The filter bubble can influence an entire nation, a specific foreign company, or a horizontal group of subjects scattered around the world. In order to analyse and understand its impact, we need to combine our data to enable a researcher (you, maybe, it is open) to discover how the companies’ algorithms work.

    div.footer 
